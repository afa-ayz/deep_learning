{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP5329 - Deep Learning \n",
    "\n",
    "## Tutorial 8 - Deep Learning Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Semester 1, 2018**\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "* To learn about the basic idea of deep learning based object detection algorithms. \n",
    "* To learn about how to use a RCNN to implement object detection tasks. \n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "* Install the tflearn library by typing command 'pip install tflearn' under your tensorflow environment.\n",
    "* Install the selectivesearch by typing command 'pip install selectivesearch' under your tensorflow environment.\n",
    "* Install the sklearn by typing command 'pip install sklearn' under your tensorflow environment.\n",
    "\n",
    "* Exercises to be completed on IPython notebook such as web-based TMPNB Ipython notebook(https://tmpnb.org).\n",
    "* Go to File->Open. Drag and drop \"Deep_Learning_Applications.ipynb\"(with '') file to the home interface and click upload.\n",
    "* To run the cell you can press Ctrl-Enter or hit the Play button at the top. \n",
    "\n",
    "Lecturers: Chang Xu\n",
    "\n",
    "Tutors: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Application - Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training AlexNet on flower17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training an AlexNet on flower17 dataset (https://github.com/ck196/tensorflow-alexnet). The pre-trained models can be download from https://drive.google.com/drive/folders/1dc8Q5pAIqtfw3oxZi275Ctj-wKBac-aV?usp=sharing (model_save.model). It might take 1 hour on a single GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dguo8417/gdlsdfz/environment/tensorflow-cpu/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np \n",
    "import selectivesearch\n",
    "from PIL import Image\n",
    "import os.path\n",
    "import skimage\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "def pil_to_nparray(pil_image):\n",
    "    pil_image.load()\n",
    "    return np.asarray(pil_image, dtype=\"float32\")\n",
    "\n",
    "def resize_image(in_image, new_width, new_height, out_image=None,\n",
    "                 resize_mode=Image.ANTIALIAS):\n",
    "    img = in_image.resize((new_width, new_height), resize_mode)\n",
    "    if out_image:\n",
    "        img.save(out_image)\n",
    "    return img\n",
    "\n",
    "# IOU Part 1\n",
    "def if_intersection(xmin_a, xmax_a, ymin_a, ymax_a, xmin_b, xmax_b, ymin_b, ymax_b):\n",
    "    if_intersect = False\n",
    "    if xmin_a < xmax_b <= xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "        if_intersect = True\n",
    "    elif xmin_a <= xmin_b < xmax_a and (ymin_a < ymax_b <= ymax_a or ymin_a <= ymin_b < ymax_a):\n",
    "        if_intersect = True\n",
    "    elif xmin_b < xmax_a <= xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "        if_intersect = True\n",
    "    elif xmin_b <= xmin_a < xmax_b and (ymin_b < ymax_a <= ymax_b or ymin_b <= ymin_a < ymax_b):\n",
    "        if_intersect = True\n",
    "    else:\n",
    "        return False\n",
    "    if if_intersect == True:\n",
    "        x_sorted_list = sorted([xmin_a, xmax_a, xmin_b, xmax_b])\n",
    "        y_sorted_list = sorted([ymin_a, ymax_a, ymin_b, ymax_b])\n",
    "        x_intersect_w = x_sorted_list[2] - x_sorted_list[1] \n",
    "        y_intersect_h = y_sorted_list[2] - y_sorted_list[1]\n",
    "        area_inter = x_intersect_w * y_intersect_h\n",
    "        return area_inter\n",
    "\n",
    "# IOU Part 2\n",
    "def IOU(ver1, vertice2):\n",
    "    # vertices in four points\n",
    "    vertice1 = [ver1[0], ver1[1], ver1[0]+ver1[2], ver1[1]+ver1[3]]\n",
    "    area_inter = if_intersection(vertice1[0], vertice1[2], vertice1[1], vertice1[3], vertice2[0], vertice2[2], vertice2[1], vertice2[3])\n",
    "    if area_inter:\n",
    "        area_1 = ver1[2] * ver1[3] \n",
    "        area_2 = vertice2[4] * vertice2[5] \n",
    "        iou = float(area_inter) / (area_1 + area_2 - area_inter)\n",
    "        return iou\n",
    "    return False\n",
    "\n",
    "# Clip Image\n",
    "def clip_pic(img, rect):\n",
    "    x = rect[0]\n",
    "    y = rect[1]\n",
    "    w = rect[2]\n",
    "    h = rect[3]\n",
    "    x_1 = x + w\n",
    "    y_1 = y + h\n",
    "    return img[x:x_1, y:y_1, :], [x, y, x_1, y_1, w, h]\n",
    "\n",
    "# Read in data and save data for Alexnet\n",
    "def load_train_proposals(datafile, num_clss, threshold = 0.5, svm = False, save=False, save_path='dataset.pkl'):\n",
    "    train_list = open(datafile,'r')\n",
    "    labels = []\n",
    "    images = []\n",
    "    for line in train_list:\n",
    "        tmp = line.strip().split(' ')\n",
    "        # tmp0 = image address\n",
    "        # tmp1 = label\n",
    "        # tmp2 = rectangle vertices\n",
    "        img = skimage.io.imread(tmp[0])\n",
    "        img_lbl, regions = selectivesearch.selective_search(\n",
    "                               img, scale=500, sigma=0.9, min_size=10)\n",
    "        candidates = set()\n",
    "        for r in regions:\n",
    "            if r['rect'] in candidates:\n",
    "                continue\n",
    "            if r['size'] < 220:\n",
    "                continue\n",
    "            proposal_img, proposal_vertice = clip_pic(img, r['rect'])\n",
    "            if len(proposal_img) == 0:\n",
    "                continue\n",
    "            # Ignore things contain 0 or not C contiguous array\n",
    "            x, y, w, h = r['rect']\n",
    "            if w == 0 or h == 0:\n",
    "                continue\n",
    "            # Check if any 0-dimension exist\n",
    "            [a, b, c] = np.shape(proposal_img)\n",
    "            if a == 0 or b == 0 or c == 0:\n",
    "                continue\n",
    "            im = Image.fromarray(proposal_img)\n",
    "            resized_proposal_img = resize_image(im, 224, 224)\n",
    "            candidates.add(r['rect'])\n",
    "            img_float = pil_to_nparray(resized_proposal_img)\n",
    "            images.append(img_float)\n",
    "            # IOU\n",
    "            ref_rect = tmp[2].split(',')\n",
    "            ref_rect_int = [int(i) for i in ref_rect]\n",
    "            iou_val = IOU(ref_rect_int, proposal_vertice)\n",
    "            # labels, let 0 represent default class, which is background\n",
    "            index = int(tmp[1])\n",
    "            if svm == False:\n",
    "                label = np.zeros(num_clss+1)\n",
    "                if iou_val < threshold:\n",
    "                    label[0] = 1\n",
    "                else:\n",
    "                    label[index] = 1\n",
    "                labels.append(label)\n",
    "            else:\n",
    "                if iou_val < threshold:\n",
    "                    labels.append(0)\n",
    "                else:\n",
    "                    labels.append(index)\n",
    "    if save:\n",
    "        pickle.dump((images, labels), open(save_path, 'wb'))\n",
    "    return images, labels\n",
    "\n",
    "def load_from_pkl(dataset_file):\n",
    "    X, Y = pickle.load(open(dataset_file, 'rb'))\n",
    "    return X,Y\n",
    "\n",
    "def load_image(img_path):\n",
    "    img = Image.open(img_path)\n",
    "    return img\n",
    "\n",
    "def resize_image(in_image, new_width, new_height, out_image=None,\n",
    "                 resize_mode=Image.ANTIALIAS):\n",
    "    img = in_image.resize((new_width, new_height), resize_mode)\n",
    "    if out_image:\n",
    "        img.save(out_image)\n",
    "    return img\n",
    "\n",
    "def pil_to_nparray(pil_image):\n",
    "    pil_image.load()\n",
    "    return np.asarray(pil_image, dtype=\"float32\")\n",
    "\n",
    "def load_data(datafile, num_clss, save=False, save_path='dataset.pkl'):\n",
    "    train_list = open(datafile,'r')\n",
    "    labels = []\n",
    "    images = []\n",
    "    for line in train_list:\n",
    "        tmp = line.strip().split(' ')\n",
    "        fpath = tmp[0]\n",
    "        print(fpath)\n",
    "        img = load_image(fpath)\n",
    "        img = resize_image(img,224,224)\n",
    "        np_img = pil_to_nparray(img)\n",
    "        images.append(np_img)\n",
    "\n",
    "        index = int(tmp[1])\n",
    "        label = np.zeros(num_clss)\n",
    "        label[index] = 1\n",
    "        labels.append(label)\n",
    "    if save:\n",
    "        pickle.dump((images, labels), open(save_path, 'wb'))\n",
    "    return images, labels\n",
    " \n",
    "def create_alexnet(num_classes):\n",
    "    # Building 'AlexNet'\n",
    "    network = input_data(shape=[None, 224, 224, 3])\n",
    "    network = conv_2d(network, 96, 11, strides=4, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = conv_2d(network, 256, 5, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = conv_2d(network, 384, 3, activation='relu')\n",
    "    network = conv_2d(network, 384, 3, activation='relu')\n",
    "    network = conv_2d(network, 256, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = fully_connected(network, 4096, activation='tanh')\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, 4096, activation='tanh')\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, num_classes, activation='softmax')\n",
    "    network = regression(network, optimizer='momentum',\n",
    "                         loss='categorical_crossentropy',\n",
    "                         learning_rate=0.001)\n",
    "    return network\n",
    "\n",
    "def train(network, X, Y):\n",
    "    # Training\n",
    "    model = tflearn.DNN(network, checkpoint_path='model_alexnet',\n",
    "                        max_checkpoints=1, tensorboard_verbose=2, tensorboard_dir='output')\n",
    "    if os.path.isfile('model_save.model'):\n",
    "        model.load('model_save.model')\n",
    "    model.fit(X, Y, n_epoch=100, validation_set=0.1, shuffle=True,\n",
    "              show_metric=True, batch_size=64, snapshot_step=200,\n",
    "              snapshot_epoch=False, run_id='alexnet_oxflowers17') # epoch = 1000\n",
    "    # Save the model\n",
    "    model.save('model_save.model')\n",
    "\n",
    "def predict(network, input_data, modelfile,images):\n",
    "    model = tflearn.DNN(network)\n",
    "    model.load(modelfile)\n",
    "    return model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Uncomment below codes to train AlexNet yourselves.\n",
    "#X, Y = load_data('train_list.txt', 17)\n",
    "#net = create_alexnet(17)\n",
    "#train(net,X,Y)## Training AlexNet on flower17\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune AlexNet on traget dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning the pre-trained AlexNet on the given dataset. The fine-tune model can be download from https://drive.google.com/drive/folders/1dc8Q5pAIqtfw3oxZi275Ctj-wKBac-aV?usp=sharing (fine_tune_model_save.model.*). It might take 20 mins on a single GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fine_tune_Alexnet(network, X, Y):\n",
    "    # Training\n",
    "    model = tflearn.DNN(network, checkpoint_path='rcnn_model_alexnet',\n",
    "                        max_checkpoints=1, tensorboard_verbose=2, tensorboard_dir='output_RCNN')\n",
    "    print(\"Loading the alexnet\")\n",
    "    model.load('model_save.model')\n",
    "    model.fit(X, Y, n_epoch=10, validation_set=0.1, shuffle=True,\n",
    "              show_metric=True, batch_size=64, snapshot_step=200,\n",
    "              snapshot_epoch=False, run_id='alexnet_rcnnflowers2') # epoch = 1000\n",
    "    # Save the model\n",
    "    model.save('fine_tune_model_save.model')\n",
    "    \n",
    "#Uncomment below codes to fine-tune AlexNet on tragets dataset.\n",
    "#print(\"Loading Data\")\n",
    "#X, Y = load_from_pkl('dataset.pkl')\n",
    "#restore = False\n",
    "#net = create_alexnet(3, restore)\n",
    "#fine_tune_Alexnet(net,X,Y)\n",
    "## Fine-tune AlexNet on traget dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting proposals and training classifiers (SVMs employed here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import pickle\n",
    "import numpy as np \n",
    "import selectivesearch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import os.path\n",
    "import skimage\n",
    "from sklearn import svm\n",
    "import preprocessing_RCNN as prep\n",
    "import os\n",
    "\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "# Load testing images\n",
    "def resize_image(in_image, new_width, new_height, out_image=None,\n",
    "                 resize_mode=Image.ANTIALIAS):\n",
    "    img = in_image.resize((new_width, new_height), resize_mode)\n",
    "    if out_image:\n",
    "        img.save(out_image)\n",
    "    return img\n",
    "\n",
    "def pil_to_nparray(pil_image):\n",
    "    pil_image.load()\n",
    "    return np.asarray(pil_image, dtype=\"float32\")\n",
    "\n",
    "def image_proposal(img_path):\n",
    "    img = skimage.io.imread(img_path)\n",
    "    img_lbl, regions = selectivesearch.selective_search(\n",
    "                       img, scale=500, sigma=0.9, min_size=10)\n",
    "    candidates = set()\n",
    "    images = []\n",
    "    vertices = []\n",
    "    for r in regions:\n",
    "        if r['rect'] in candidates:\n",
    "            continue\n",
    "        if r['size'] < 220:\n",
    "            continue\n",
    "        proposal_img, proposal_vertice = clip_pic(img, r['rect'])\n",
    "        # Delete Empty array\n",
    "        if len(proposal_img) == 0:\n",
    "            continue\n",
    "        # Ignore things contain 0 or not C contiguous array\n",
    "        x, y, w, h = r['rect']\n",
    "        if w == 0 or h == 0:\n",
    "            continue\n",
    "        # Check if any 0-dimension exist\n",
    "        [a, b, c] = np.shape(proposal_img)\n",
    "        if a == 0 or b == 0 or c == 0:\n",
    "            continue\n",
    "        im = Image.fromarray(proposal_img)\n",
    "        resized_proposal_img = resize_image(im, 224, 224)\n",
    "        candidates.add(r['rect'])\n",
    "        img_float = pil_to_nparray(resized_proposal_img)\n",
    "        images.append(img_float)\n",
    "        vertices.append(r['rect'])\n",
    "    return images, vertices\n",
    "\n",
    "# Load training images\n",
    "def generate_single_svm_train(one_class_train_file):\n",
    "    trainfile = one_class_train_file\n",
    "    savepath = one_class_train_file.replace('txt', 'pkl')\n",
    "    images = []\n",
    "    Y = []\n",
    "    if os.path.isfile(savepath):\n",
    "        print(\"restoring svm dataset \" + savepath)\n",
    "        images, Y = load_from_pkl(savepath)\n",
    "    else:\n",
    "        print(\"loading svm dataset \" + savepath)\n",
    "        images, Y = load_train_proposals(trainfile, 2, threshold=0.3, svm=True, save=True, save_path=savepath)\n",
    "    return images, Y\n",
    "    \n",
    "# Use a already trained alexnet with the last layer redesigned\n",
    "def create_alexnet_features(num_classes, restore=False):\n",
    "    # Building 'AlexNet'\n",
    "    network = input_data(shape=[None, 224, 224, 3])\n",
    "    network = conv_2d(network, 96, 11, strides=4, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = conv_2d(network, 256, 5, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = conv_2d(network, 384, 3, activation='relu')\n",
    "    network = conv_2d(network, 384, 3, activation='relu')\n",
    "    network = conv_2d(network, 256, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = fully_connected(network, 4096, activation='tanh')\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, 4096, activation='tanh')\n",
    "    network = regression(network, optimizer='momentum',\n",
    "                         loss='categorical_crossentropy',\n",
    "                         learning_rate=0.001)\n",
    "    return network\n",
    "\n",
    "# Construct cascade svms\n",
    "\n",
    "def train_svms(train_file_folder, model):\n",
    "    listings = os.listdir(train_file_folder)\n",
    "    svms = []\n",
    "    for train_file in listings:\n",
    "        if \"pkl\" in train_file:\n",
    "            continue\n",
    "        X, Y = generate_single_svm_train(train_file_folder+train_file)\n",
    "        train_features = []\n",
    "        for i in X:\n",
    "            feats = model.predict([i])\n",
    "            train_features.append(feats[0])\n",
    "        print(\"feature dimension\")\n",
    "        print(np.shape(train_features))\n",
    "        clf = svm.LinearSVC()\n",
    "        print(\"fit svm\")\n",
    "        clf.fit(train_features, Y)\n",
    "        svms.append(clf)\n",
    "    return svms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file_folder = 'svm_train/'\n",
    "# create and save proposals\n",
    "net = create_alexnet_features(3)\n",
    "model = tflearn.DNN(net)\n",
    "model.load('fine_tune_model_save.model')\n",
    "# training svm classfiers to classify selected proposals\n",
    "svms = train_svms(train_file_folder, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a test image, we first select multiple proposals using selective search. Then, the fine-tuned AlexNet are utilized to extract features of these proposals. Finally, trained classifiers (i.e., svm) are used to detect objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_path = 'testimg.jpg'\n",
    "imgs, verts = image_proposal(img_path)\n",
    "features = model.predict(imgs)\n",
    "print(\"predict image:\")\n",
    "print(np.shape(features))\n",
    "results = []\n",
    "results_label = []\n",
    "count = 0\n",
    "for f in features:\n",
    "    for i in svms:\n",
    "        pred = i.predict([f])\n",
    "        print(pred)\n",
    "        if pred[0] != 0:\n",
    "            results.append(verts[count])\n",
    "            results_label.append(pred[0])\n",
    "    count += 1\n",
    "img = skimage.io.imread(img_path)\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(6, 6))\n",
    "ax.imshow(img)\n",
    "for x, y, w, h in results:\n",
    "    rect = mpatches.Rectangle(\n",
    "        (x, y), w, h, fill=False, edgecolor='red', linewidth=1)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "* For each object, multiple proposals are selected. How can we remove most of them and retain the desired one?\n",
    "* Based on the framework of RCNN, attempting to understand the ideas of Fast-RCNN (https://arxiv.org/abs/1504.08083) and Faster-RCNN (https://arxiv.org/abs/1506.01497)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
